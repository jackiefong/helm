# Default values for spark-thrift-server.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

nameOverride: ""
fullnameOverride: ""

##  
# Service Account and RBAC
##
# The helm chart will auto create and use the service account/rbac, keep setting to true
serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
rbac:
  create: true
##  
# metastore configuration  
##
historyserver:
  enabled: false
metastore:
  includeKeyAndSecret: true
  # Init Schema (only for the first time setup)
  replicaCount: 1
  initSchema:
    # Set to false after init schema (Doesn't hurt if you keep enable to true, but it will create a Kubernetes job)
    enabled: false
    # Current dbtype mysql or postgres (Required)
    dbType: "postgres"
    # DB username (Required)
    userName: "postgres"
    # jdbc url (Required)
    url: "jdbc:postgresql://postgresql:5432/metastore_db?useSSL=false"
    # the job setup to use DB_PASSWORD as env variable for the database password (Required)
    env:
      - name: DB_PASSWORD
        valueFrom:
          secretKeyRef:
            name: data-lake
            key: postgresql-password
  busyboxImage:
    repository:  busybox
    tag: "1.34.0"  
  image:  
    repository: fongjackie/hivemetastore
    pullPolicy: IfNotPresent
    tag: "3.0.0"
  # The Secret for core site and metastore site xml, currently metastore supports mysql and postgresql (Required)
  coreSiteSecret: data-lake
  metastoreSiteSecret: data-lake
  nodeSelector: {}
  tolerations: {}
  resources:
    requests:
      memory: "500Mi"
      cpu: 500m
    limits:
      memory: "1024Mi"
      cpu: 1      
  # Env variable, such as AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY
  env:
    - name: AWS_ACCESS_KEY_ID
      valueFrom:
        secretKeyRef:
          name: data-lake
          key: s3-access
    - name: AWS_SECRET_ACCESS_KEY
      valueFrom:
        secretKeyRef:
          name: data-lake
          key: s3-secret
##  
# Spark Thrift Server configuration  
##
driver:
  includeKeyAndSecret: true # when true, please eprovide s3env setting
  s3Provider: com.amazonaws.auth.WebIdentityTokenCredentialsProvider
  kubectlImage:
    repository:  bitnami/kubectl
    tag: "1.18.19"
  busyboxImage:
    repository:  busybox
    tag: "1.34.0"
  image:
    repository:  fongjackie/spark
    pullPolicy: IfNotPresent
    tag: "3.1.2"
  imagePullSecrets: {}
  # Kubernetes api server url (required)  
  k8s: "k8s://https://kubernetes.default.svc"
  # Env variable for the cronjob, for example, if the job files are at s3, include env variable such as AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY
  s3env:
    - name: AWS_ACCESS_KEY_ID
      valueFrom:
        secretKeyRef:
          name: data-lake
          key: s3-access
    - name: AWS_SECRET_ACCESS_KEY
      valueFrom:
        secretKeyRef:
          name: data-lake
          key: s3-secret          
  env:
    - name: STS_ADMIN_PASSWORD
      valueFrom:
        secretKeyRef:
          name: data-lake
          key: sts_admin_password  
  resources:
    limits:
      memory: 1Gi
    requests:
      cpu: '1'
      memory: 1Gi  
  nodeSelector: {}
  tolerations: {}
  spark:
    namespace: data-lake
    s3endpoint: http://minio:9000
    s3logbucket: s3a://data-lake-log-bucket
    s3datalakebucket: s3a://data-lake-bucket
    eventLog: true
    customconfig:      
    datalakeconfig:
      # custom config for performance tuning
      - --conf
      - spark.sql.thriftServer.incrementalCollect=true
      - --conf
      - spark.scheduler.pool=stspool
      - --conf
      - spark.scheduler.mode=FAIR
      - --conf
      - spark.scheduler.allocation.file=/opt/spark/spark-submit-app/scheduler.xml
      - --conf
      - spark.sql.broadcastTimeout=2000
      - --conf
      - spark.sql.shuffle.partitions=13
    metricconfig:
      # Setting for monitoring
      - --conf
      -  spark.metrics.namespace="datalake"
      - --conf
      - spark.ui.prometheus.enabled=true
      - --conf
      - spark.metrics.staticSources.enabled=true
      - --conf
      - spark.metrics.appStatusSource.enabled=true 
    hiveconf:
      - hive.exec.stagingdir=/runtime/tmp
      - --hiveconf
      - hive.exec.scratchdir=/runtime/tmp 
    pvc:
      # Dynamic pvc setting
      - --conf
      - spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-localdirpvc.mount.path=/localdir
      - --conf
      - spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-localdirpvc.mount.readOnly=false
      - --conf
      - spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-localdirpvc.mount.subPath=localdir
      - --conf
      - spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-localdirpvc.options.claimName=OnDemand
      - --conf
      - spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-localdirpvc.options.storageClass=default
      - --conf
      - spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-localdirpvc.options.sizeLimit=200Gi
    kubernetes:
      # config spark resources, such as executor instance, memory and cores. Please refer to : https://spark.apache.org/docs/3.0.0-preview/configuration.html for more information
      resource:        
        # Change Namespace to match k8s namespace (Require for Spark)
        - --conf
        - spark.kubernetes.namespace={{ .Values.driver.spark.namespace}}
        # Driver CPU/Memory, not likely need to change for scaling 
        - --conf
        - spark.driver.cores=1
        - --conf
        - spark.driver.memory=1G
        # Executer CPU/Memory, only need to change spark.executor.instance, always increase by 6 core 40G
        - --conf
        - spark.executor.instances=1
        - --conf
        - spark.executor.memory=1G  # Most efficent spark memory allocation (K8s will schedule overhead for pod, 40G will allocation 44G Pod)
        - --conf
        - spark.kubernetes.executor.limit.memory=1G
        - --conf
        - spark.executor.cores=1  # Most efficent spark cpu allocation
        - --conf
        - spark.kubernetes.executor.limit.cores=1 
      executor:
        # the secret reference for the executor, for example, AWS_ACCESS_KEY_ID
        secretKeyRef:
          - --conf
          - spark.kubernetes.executor.secretKeyRef.AWS_ACCESS_KEY_ID=data-lake:s3-access
          - --conf
          - spark.kubernetes.executor.secretKeyRef.AWS_SECRET_ACCESS_KEY=data-lake:s3-secret
    hadoop:
       # config to access S3
      fs:
        - --conf
        - spark.hadoop.fs.s3a.connection.ssl.enabled=false        
        - --conf
        - spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
        - --conf
        - spark.hadoop.fs.s3a.fast.upload=true
        - --conf
        - spark.hadoop.fs.s3a.path.style.access=true
      fsconfig:
          # Enable or disable Spark Logging to S3
          - --conf
          - spark.eventLog.enabled={{ .Values.driver.spark.eventLog}}           
          # end point ex: AWS(http://s3.amazonaws.com) minIO(http://minio:9000)
          - --conf
          - spark.hadoop.fs.s3a.endpoint={{ .Values.driver.spark.s3endpoint}}
          # config for logging bucket
          - --conf
          - spark.eventLog.dir={{ .Values.driver.spark.s3logbucket}}/eventLogFolder
          # config for datalake bucket
          - --conf
          - spark.hadoop.fs.defaultFS={{ .Values.driver.spark.s3datalakebucket}}
          - --conf
          - spark.kubernetes.file.upload.path={{ .Values.driver.spark.s3datalakebucket}}/spark-thrift-server
          - --conf
          - spark.sql.warehouse.dir={{ .Values.driver.spark.s3datalakebucket}}/warehouse        
      # config for hive
      hive:
        - --conf
        - spark.hadoop.metastore.catalog.default=spark
        - --conf
        - spark.hadoop.hive.metastore.client.connect.retry.delay=5
        - --conf
        - spark.hadoop.hive.metastore.client.socket.timeout=1800        
        - --conf
        - spark.hadoop.hive.server2.thrift.http.port=10002
        - --conf
        - spark.hadoop.hive.server2.thrift.port=10016
        - --conf
        - spark.hadoop.hive.server2.transport.mode=binary
        - --conf
        - spark.hadoop.hive.execution.engine=spark
        - --conf
        - spark.hadoop.hive.input.format=io.delta.hive.HiveInputFormat
        - --conf
        - spark.hadoop.hive.tez.input.format=io.delta.hive.HiveInputFormat